{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import tikzplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import efficientnet.tfkeras as efn\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.145377828922"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.877576671694303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \" return an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45eb468861b34c6eb05061a5bc54cdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \" read DICOM dataset and return resize images of size (512,512,3)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    resized_image = np.stack((resized_image,)*3, axis = -1)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        #x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights='imagenet',include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False),\n",
    "        #'RNet50': resnet50.ResNet50(input_shape=shape,weights=None,include_top=False),\n",
    "        #'V16': vgg16.VGG16(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 3), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_model(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b0 (Model)         (None, 16, 16, 1280) 4049564     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           efficientnet-b0[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 4)            0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1284)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1284)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1285        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,050,849\n",
      "Trainable params: 4,008,833\n",
      "Non-trainable params: 42,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b0'\n",
    "base_model = build_model(shape=(512, 512, 3), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True\n",
    "tr_p, vl_p = train_test_split(P, shuffle=True, train_size= 0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6074\n",
      "Epoch 00001: val_loss improved from inf to 5.72756, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 13s 416ms/step - loss: 4.6074 - val_loss: 5.7276 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1683\n",
      "Epoch 00002: val_loss improved from 5.72756 to 5.21481, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 14s 430ms/step - loss: 4.1683 - val_loss: 5.2148 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3663\n",
      "Epoch 00003: val_loss improved from 5.21481 to 4.38415, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 381ms/step - loss: 4.3663 - val_loss: 4.3842 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5549\n",
      "Epoch 00004: val_loss did not improve from 4.38415\n",
      "32/32 [==============================] - 10s 304ms/step - loss: 4.5549 - val_loss: 6.2573 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7297\n",
      "Epoch 00005: val_loss did not improve from 4.38415\n",
      "32/32 [==============================] - 9s 273ms/step - loss: 4.7297 - val_loss: 6.7128 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2636\n",
      "Epoch 00006: val_loss did not improve from 4.38415\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 5.2636 - val_loss: 5.3732 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4706\n",
      "Epoch 00007: val_loss improved from 4.38415 to 3.91247, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 372ms/step - loss: 4.4706 - val_loss: 3.9125 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8092\n",
      "Epoch 00008: val_loss improved from 3.91247 to 3.78508, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 4.8092 - val_loss: 3.7851 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1700\n",
      "Epoch 00009: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 10s 298ms/step - loss: 5.1700 - val_loss: 5.4998 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2704\n",
      "Epoch 00010: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 8s 262ms/step - loss: 4.2704 - val_loss: 4.7145 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5341\n",
      "Epoch 00011: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 4.5341 - val_loss: 3.8167 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1299\n",
      "Epoch 00012: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 9s 285ms/step - loss: 4.1299 - val_loss: 4.7965 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0364\n",
      "Epoch 00013: val_loss did not improve from 3.78508\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 9s 288ms/step - loss: 5.0364 - val_loss: 3.8258 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5226\n",
      "Epoch 00014: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 8s 261ms/step - loss: 4.5226 - val_loss: 4.2105 - lr: 5.0000e-04\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4656\n",
      "Epoch 00015: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 9s 270ms/step - loss: 4.4656 - val_loss: 4.4093 - lr: 5.0000e-04\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8055\n",
      "Epoch 00016: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 8s 252ms/step - loss: 3.8055 - val_loss: 3.9928 - lr: 5.0000e-04\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7304\n",
      "Epoch 00017: val_loss did not improve from 3.78508\n",
      "32/32 [==============================] - 8s 261ms/step - loss: 4.7304 - val_loss: 4.9420 - lr: 5.0000e-04\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3227\n",
      "Epoch 00018: val_loss improved from 3.78508 to 3.65778, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 11s 355ms/step - loss: 4.3227 - val_loss: 3.6578 - lr: 5.0000e-04\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7704\n",
      "Epoch 00019: val_loss did not improve from 3.65778\n",
      "32/32 [==============================] - 9s 268ms/step - loss: 4.7704 - val_loss: 4.6293 - lr: 5.0000e-04\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7538\n",
      "Epoch 00020: val_loss did not improve from 3.65778\n",
      "32/32 [==============================] - 8s 257ms/step - loss: 4.7538 - val_loss: 4.0691 - lr: 5.0000e-04\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7208\n",
      "Epoch 00021: val_loss did not improve from 3.65778\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 4.7208 - val_loss: 4.7368 - lr: 5.0000e-04\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8393\n",
      "Epoch 00022: val_loss did not improve from 3.65778\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 3.8393 - val_loss: 4.1926 - lr: 5.0000e-04\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8425\n",
      "Epoch 00023: val_loss did not improve from 3.65778\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 4.8425 - val_loss: 4.5235 - lr: 5.0000e-04\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2019\n",
      "Epoch 00024: val_loss improved from 3.65778 to 3.40009, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 369ms/step - loss: 4.2019 - val_loss: 3.4001 - lr: 2.5000e-04\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8986\n",
      "Epoch 00025: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 260ms/step - loss: 3.8986 - val_loss: 4.7558 - lr: 2.5000e-04\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3608\n",
      "Epoch 00026: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 4.3608 - val_loss: 3.8200 - lr: 2.5000e-04\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2337\n",
      "Epoch 00027: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 4.2337 - val_loss: 4.3774 - lr: 2.5000e-04\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2863\n",
      "Epoch 00028: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 255ms/step - loss: 4.2863 - val_loss: 4.5771 - lr: 2.5000e-04\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9438\n",
      "Epoch 00029: val_loss did not improve from 3.40009\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 3.9438 - val_loss: 3.8163 - lr: 2.5000e-04\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6108\n",
      "Epoch 00030: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 3.6108 - val_loss: 4.3505 - lr: 1.2500e-04\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1592\n",
      "Epoch 00031: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 4.1592 - val_loss: 4.5520 - lr: 1.2500e-04\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7559\n",
      "Epoch 00032: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 251ms/step - loss: 3.7559 - val_loss: 4.0126 - lr: 1.2500e-04\n",
      "Epoch 33/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8471\n",
      "Epoch 00033: val_loss did not improve from 3.40009\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 3.8471 - val_loss: 3.7295 - lr: 1.2500e-04\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 4.2696\n",
      "Epoch 00034: val_loss did not improve from 3.40009\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.2696 - val_loss: 3.6740 - lr: 1.2500e-04\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5457\n",
      "Epoch 00035: val_loss improved from 3.40009 to 3.27814, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 11s 333ms/step - loss: 3.5457 - val_loss: 3.2781 - lr: 6.2500e-05\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1622\n",
      "Epoch 00036: val_loss did not improve from 3.27814\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 3.1622 - val_loss: 3.6928 - lr: 6.2500e-05\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5672\n",
      "Epoch 00037: val_loss did not improve from 3.27814\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.5672 - val_loss: 3.4657 - lr: 6.2500e-05\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4903\n",
      "Epoch 00038: val_loss improved from 3.27814 to 3.15280, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 11s 334ms/step - loss: 3.4903 - val_loss: 3.1528 - lr: 6.2500e-05\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6348\n",
      "Epoch 00039: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 3.6348 - val_loss: 4.0487 - lr: 6.2500e-05\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5887\n",
      "Epoch 00040: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.5887 - val_loss: 3.6786 - lr: 6.2500e-05\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2882\n",
      "Epoch 00041: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.2882 - val_loss: 3.3850 - lr: 6.2500e-05\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6745\n",
      "Epoch 00042: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 3.6745 - val_loss: 4.1128 - lr: 6.2500e-05\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0726\n",
      "Epoch 00043: val_loss did not improve from 3.15280\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 4.0726 - val_loss: 3.6779 - lr: 6.2500e-05\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5803\n",
      "Epoch 00044: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 3.5803 - val_loss: 3.9058 - lr: 3.1250e-05\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1237\n",
      "Epoch 00045: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 4.1237 - val_loss: 3.5314 - lr: 3.1250e-05\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2103\n",
      "Epoch 00046: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.2103 - val_loss: 3.5729 - lr: 3.1250e-05\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5827\n",
      "Epoch 00047: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 252ms/step - loss: 3.5827 - val_loss: 3.4234 - lr: 3.1250e-05\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5482\n",
      "Epoch 00048: val_loss did not improve from 3.15280\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 3.5482 - val_loss: 4.1170 - lr: 3.1250e-05\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8180\n",
      "Epoch 00049: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 3.8180 - val_loss: 4.5010 - lr: 1.5625e-05\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0467\n",
      "Epoch 00050: val_loss did not improve from 3.15280\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 3.0467 - val_loss: 4.0487 - lr: 1.5625e-05\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2128\n",
      "Epoch 00051: val_loss improved from 3.15280 to 2.98880, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 11s 332ms/step - loss: 4.2128 - val_loss: 2.9888 - lr: 1.5625e-05\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6765\n",
      "Epoch 00052: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 262ms/step - loss: 3.6765 - val_loss: 3.7712 - lr: 1.5625e-05\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7650\n",
      "Epoch 00053: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 3.7650 - val_loss: 3.3208 - lr: 1.5625e-05\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7834\n",
      "Epoch 00054: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.7834 - val_loss: 3.2174 - lr: 1.5625e-05\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9835\n",
      "Epoch 00055: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.9835 - val_loss: 3.1978 - lr: 1.5625e-05\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2965\n",
      "Epoch 00056: val_loss did not improve from 2.98880\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.2965 - val_loss: 3.1582 - lr: 1.5625e-05\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3545\n",
      "Epoch 00057: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 3.3545 - val_loss: 3.1766 - lr: 7.8125e-06\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3681\n",
      "Epoch 00058: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 3.3681 - val_loss: 3.6503 - lr: 7.8125e-06\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4481\n",
      "Epoch 00059: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 3.4481 - val_loss: 3.7493 - lr: 7.8125e-06\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3156\n",
      "Epoch 00060: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.3156 - val_loss: 3.4747 - lr: 7.8125e-06\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1741\n",
      "Epoch 00061: val_loss did not improve from 2.98880\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.1741 - val_loss: 3.4570 - lr: 7.8125e-06\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9846\n",
      "Epoch 00062: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 3.9846 - val_loss: 3.4697 - lr: 3.9063e-06\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5728\n",
      "Epoch 00063: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 3.5728 - val_loss: 3.5165 - lr: 3.9063e-06\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6801\n",
      "Epoch 00064: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 3.6801 - val_loss: 3.5146 - lr: 3.9063e-06\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1852\n",
      "Epoch 00065: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 4.1852 - val_loss: 3.4075 - lr: 3.9063e-06\n",
      "Epoch 66/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.9735\n",
      "Epoch 00066: val_loss did not improve from 2.98880\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 2.9735 - val_loss: 3.0168 - lr: 3.9063e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7179\n",
      "Epoch 00067: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 3.7179 - val_loss: 3.9223 - lr: 1.9531e-06\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0841\n",
      "Epoch 00068: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 4.0841 - val_loss: 3.2931 - lr: 1.9531e-06\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6760\n",
      "Epoch 00069: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.6760 - val_loss: 3.6573 - lr: 1.9531e-06\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6977\n",
      "Epoch 00070: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 3.6977 - val_loss: 3.0463 - lr: 1.9531e-06\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8223\n",
      "Epoch 00071: val_loss did not improve from 2.98880\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 8s 235ms/step - loss: 3.8223 - val_loss: 3.9322 - lr: 1.9531e-06\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4005\n",
      "Epoch 00072: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.4005 - val_loss: 3.0837 - lr: 9.7656e-07\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2232\n",
      "Epoch 00073: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 3.2232 - val_loss: 3.3249 - lr: 9.7656e-07\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5714\n",
      "Epoch 00074: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 235ms/step - loss: 3.5714 - val_loss: 3.4371 - lr: 9.7656e-07\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0721\n",
      "Epoch 00075: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 3.0721 - val_loss: 3.1817 - lr: 9.7656e-07\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2877\n",
      "Epoch 00076: val_loss did not improve from 2.98880\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.2877 - val_loss: 3.7891 - lr: 9.7656e-07\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6022\n",
      "Epoch 00077: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 3.6022 - val_loss: 3.4495 - lr: 4.8828e-07\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7060\n",
      "Epoch 00078: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 3.7060 - val_loss: 3.1597 - lr: 4.8828e-07\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6512\n",
      "Epoch 00079: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 231ms/step - loss: 3.6512 - val_loss: 3.4065 - lr: 4.8828e-07\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3762\n",
      "Epoch 00080: val_loss did not improve from 2.98880\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 3.3762 - val_loss: 3.7085 - lr: 4.8828e-07\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=tr_p, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'EffNet_b0_history_80_epoch_imagenet.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'EffNet_b0_history_80_epoch_imagenet.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'C:/Users/Monir/Documents/CSE499/results_and_figures/EfficientNet/B0/'\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_imagenet.png')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_80_epoch_loss_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.85):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_smooth_imagenet.png')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_smooth_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_80_epoch_loss_smooth_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(fvc_true, fvc_pred, sigma):\n",
    "    sigma_clip = np.maximum(sigma, 70)\n",
    "    delta = np.abs(fvc_true - fvc_pred)\n",
    "    delta = np.minimum(delta, 1000)\n",
    "    sq2 = np.sqrt(2)\n",
    "    metric = (delta / sigma_clip)*sq2 + np.log(sigma_clip* sq2)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0e0246fead4c659ad67200ebb717d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5322737494385015\n",
      "6.526786798490927\n",
      "6.531869706535866\n",
      "6.5353274541244115\n",
      "6.551069724778402\n",
      "6.565217844382884\n",
      "6.574611682170435\n",
      "6.586950738004805\n",
      "6.600802164378043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = []\n",
    "for q in tqdm(range(1, 10)):\n",
    "    m = []\n",
    "    for p in vl_p:\n",
    "        x = [] \n",
    "        tab = [] \n",
    "        \n",
    "        if p in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n",
    "            continue\n",
    "        for i in os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/'):\n",
    "            x.append(get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/{i}')) \n",
    "            tab.append(get_tab(train.loc[train.Patient == p, :])) \n",
    "        tab = np.array(tab) \n",
    "    \n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        _a = model.predict([x, tab]) \n",
    "        a = np.quantile(_a, q / 10)\n",
    "        \n",
    "        percent_true = train.Percent.values[train.Patient == p]\n",
    "        fvc_true = train.FVC.values[train.Patient == p]\n",
    "        weeks_true = train.Weeks.values[train.Patient == p]\n",
    "        \n",
    "        fvc = a * (weeks_true - weeks_true[0]) + fvc_true[0]\n",
    "        percent = percent_true[0] - a * abs(weeks_true - weeks_true[0])\n",
    "        m.append(score(fvc_true, fvc, percent))\n",
    "    print(np.mean(m))\n",
    "    metric.append(np.mean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (np.argmin(metric) + 1)/ 10\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week   FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  2000         100\n",
       "1  ID00421637202311550012437_-12  2000         100\n",
       "2  ID00422637202311677017371_-12  2000         100\n",
       "3  ID00423637202312137826377_-12  2000         100\n",
       "4  ID00426637202313170790466_-12  2000         100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/sample_submission.csv') \n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>6</td>\n",
       "      <td>3020</td>\n",
       "      <td>70.186855</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>82.045291</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371</td>\n",
       "      <td>6</td>\n",
       "      <td>1930</td>\n",
       "      <td>76.672493</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377</td>\n",
       "      <td>17</td>\n",
       "      <td>3294</td>\n",
       "      <td>79.258903</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>0</td>\n",
       "      <td>2925</td>\n",
       "      <td>71.824968</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00419637202311204720264      6  3020  70.186855   73  Male     Ex-smoker\n",
       "1  ID00421637202311550012437     15  2739  82.045291   68  Male     Ex-smoker\n",
       "2  ID00422637202311677017371      6  1930  76.672493   73  Male     Ex-smoker\n",
       "3  ID00423637202312137826377     17  3294  79.258903   72  Male     Ex-smoker\n",
       "4  ID00426637202313170790466      0  2925  71.824968   73  Male  Never smoked"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/test.csv') \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test, B_test, P_test, W, FVC, STD, WEEK = {},{},{},{},{},{},{} \n",
    "\n",
    "for p in test.Patient.unique():\n",
    "    x = [] \n",
    "    tab = [] \n",
    "    for i in os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/test/{p}/'):\n",
    "        x.append(get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/test/{p}/{i}')) \n",
    "        tab.append(get_tab(test.loc[test.Patient == p, :])) \n",
    "    tab = np.array(tab) \n",
    "            \n",
    "    x = np.expand_dims(x, axis=-1) \n",
    "    _a = model.predict([x, tab]) \n",
    "    a = np.quantile(_a, q)\n",
    "    A_test[p] = a\n",
    "    B_test[p] = test.FVC.values[test.Patient == p] - a*test.Weeks.values[test.Patient == p]\n",
    "    P_test[p] = test.Percent.values[test.Patient == p] \n",
    "    WEEK[p] = test.Weeks.values[test.Patient == p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sub.Patient_Week.values:\n",
    "    p, w = k.split('_')\n",
    "    w = int(w) \n",
    "    \n",
    "    fvc = A_test[p] * w + B_test[p]\n",
    "    sub.loc[sub.Patient_Week == k, 'FVC'] = fvc\n",
    "    sub.loc[sub.Patient_Week == k, 'Confidence'] = (\n",
    "        P_test[p] - A_test[p] * abs(WEEK[p] - w) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>3060.059294</td>\n",
       "      <td>110.246149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2774.485768</td>\n",
       "      <td>117.531059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>2006.904271</td>\n",
       "      <td>153.576764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>3587.278950</td>\n",
       "      <td>372.537853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2961.030126</td>\n",
       "      <td>107.855094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week          FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  3060.059294  110.246149\n",
       "1  ID00421637202311550012437_-12  2774.485768  117.531059\n",
       "2  ID00422637202311677017371_-12  2006.904271  153.576764\n",
       "3  ID00423637202312137826377_-12  3587.278950  372.537853\n",
       "4  ID00426637202313170790466_-12  2961.030126  107.855094"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add infos\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"D:/CSE499/osic-pulmonary-fibrosis-progression\"\n",
    "BATCH_SIZE=128\n",
    "\n",
    "tr = pd.read_csv(f\"{ROOT}/train.csv\")\n",
    "tr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "chunk = pd.read_csv(f\"{ROOT}/test.csv\")\n",
    "\n",
    "print(\"add infos\")\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "sub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\n",
    "sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['WHERE'] = 'train'\n",
    "chunk['WHERE'] = 'val'\n",
    "sub['WHERE'] = 'test'\n",
    "data = tr.append([chunk, sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1535, 8) (5, 8) (730, 10) (2270, 10)\n",
      "176 5 5 176\n"
     ]
    }
   ],
   "source": [
    "print(tr.shape, chunk.shape, sub.shape, data.shape)\n",
    "print(tr.Patient.nunique(), chunk.Patient.nunique(), sub.Patient.nunique(), \n",
    "      data.Patient.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_week'] = data['Weeks']\n",
    "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
    "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data.loc[data.Weeks == data.min_week]\n",
    "base = base[['Patient','FVC']].copy()\n",
    "base.columns = ['Patient','min_FVC']\n",
    "base['nb'] = 1\n",
    "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
    "base = base[base.nb==1]\n",
    "base.drop('nb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(base, on='Patient', how='left')\n",
    "data['base_week'] = data['Weeks'] - data['min_week']\n",
    "del base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['Sex','SmokingStatus'] #,'Age'\n",
    "FE = []\n",
    "for col in COLS:\n",
    "    for mod in data[col].unique():\n",
    "        FE.append(mod)\n",
    "        data[mod] = (data[col] == mod).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
    "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
    "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
    "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
    "FE += ['age','percent','week','BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = data.loc[data.WHERE=='train']\n",
    "chunk = data.loc[data.WHERE=='val']\n",
    "sub = data.loc[data.WHERE=='test']\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1535, 22), (5, 22), (730, 22))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, chunk.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return K.mean(metric)\n",
    "\n",
    "def qloss(y_true, y_pred):\n",
    "    qs = [0.2, 0.50, 0.8]\n",
    "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "    e = y_true - y_pred\n",
    "    v = tf.maximum(q*e, (q-1)*e)\n",
    "    return K.mean(v)\n",
    "\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def laplace_log_likelihood(actual_fvc, predicted_fvc, confidence, return_values = False):\n",
    "    \"\"\"\n",
    "    Calculates the modified Laplace Log Likelihood score for this competition.\n",
    "    \"\"\"\n",
    "    sd_clipped = np.maximum(confidence, 70)\n",
    "    delta = np.minimum(np.abs(actual_fvc - predicted_fvc), 1000)\n",
    "    metric = - np.sqrt(2) * delta / sd_clipped - np.log(np.sqrt(2) * sd_clipped)\n",
    "\n",
    "    if return_values:\n",
    "        return metric\n",
    "    else:\n",
    "        return np.mean(metric)\n",
    "\n",
    "def make_model(nh):\n",
    "    z = L.Input((nh,), name=\"Patient\")\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d1\")(z)\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d2\")(x)\n",
    "    p1 = L.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
    "    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
    "    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                     name=\"preds\")([p1, p2])\n",
    "    \n",
    "    model = M.Model(z, preds, name=\"CNN\")\n",
    "    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n",
    "    model.compile(loss=mloss(0.8), optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), metrics=[score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET TRAINING DATA AND TARGET VALUE\n",
    "\n",
    "# get target value\n",
    "y  = tr['FVC'].values\n",
    "\n",
    "# get training & test data\n",
    "X_train = tr[FE].values\n",
    "X_test = sub[FE].values\n",
    "\n",
    "\n",
    "nh = X_train.shape[1]\n",
    "\n",
    "# instantiate target arrays\n",
    "train_preds = np.zeros((X_train.shape[0], 3))\n",
    "test_preds = np.zeros((X_test.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Patient (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "d1 (Dense)                      (None, 100)          1000        Patient[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "d2 (Dense)                      (None, 100)          10100       d1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "p1 (Dense)                      (None, 3)            303         d2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "p2 (Dense)                      (None, 3)            303         d2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "preds (Lambda)                  (None, 3)            0           p1[0][0]                         \n",
      "                                                                 p2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 11,706\n",
      "Trainable params: 11,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "11706\n"
     ]
    }
   ],
   "source": [
    "net = make_model(nh)\n",
    "print(net.summary())\n",
    "print(net.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "FOLD 2\n",
      "FOLD 3\n",
      "FOLD 4\n",
      "FOLD 5\n"
     ]
    }
   ],
   "source": [
    "model_cnt = 1\n",
    "# instantiate target arrays\n",
    "globals()['train_preds_{}'.format(model_cnt)] = np.zeros((X_train.shape[0], 3))\n",
    "globals()['test_preds_{}'.format(model_cnt)] = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "NFOLD = 5\n",
    "gkf = GroupKFold(n_splits=NFOLD)\n",
    "groups = tr['Patient'].values\n",
    "\n",
    "cnt = 0\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE=128\n",
    "for tr_idx, val_idx in gkf.split(X_train, y, groups):\n",
    "    cnt += 1\n",
    "    print(f\"FOLD {cnt}\")\n",
    "    net = make_model(nh)\n",
    "    net.fit(X_train[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "            validation_data=(X_train[val_idx], y[val_idx]), verbose=0) #\n",
    "#     print(\"train\", net.evaluate(X_train[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "#     print(\"val\", net.evaluate(X_train[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "#     print(\"predict val...\")\n",
    "    globals()['train_preds_{}'.format(model_cnt)][val_idx] = net.predict(X_train[val_idx], batch_size=BATCH_SIZE, verbose=0)\n",
    "#     print(\"predict test...\")\n",
    "    globals()['test_preds_{}'.format(model_cnt)] += net.predict(X_test, batch_size=BATCH_SIZE, verbose=0) / NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score:  -6.729124815477694\n"
     ]
    }
   ],
   "source": [
    "predicted_fvc = globals()['train_preds_{}'.format(model_cnt)][:,1]\n",
    "confidence = globals()['train_preds_{}'.format(model_cnt)][:,2]-globals()['train_preds_{}'.format(model_cnt)][:,0]\n",
    "model_score = laplace_log_likelihood(actual_fvc = y, predicted_fvc = predicted_fvc, confidence = confidence,\n",
    "                       return_values = False)\n",
    "print('Overall Score: ', model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
